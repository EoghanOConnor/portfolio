<!DOCTYPE HTML>

<html>
	<head>
		<title>Eoghan O'Connor Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body id="top">

			<!-- Banner -->
			
				<section id="banner" data-video="images/banner">
					<div class="inner">
						<header>
							<h1>Eoghan O'Connor</h1>
							<p>I'm a Computer Vision Engineer with with first-class honours in both MSc. in Artificial Intelligence and B.Eng. in Electronic & Computer Engineering.
								I've expertise in developing Artificial Intelligence applications including Computer vision, Reinforcement learning, and machine learning.
								</p>
								
							<p>The following snippets describe some of my projects </p>
								<p>Take a look!</p>


							
							 
						</header>
						<a href="#main" class="more">Learn More</a>
					</div>
				</section>

			<!-- Main -->
				<div id="main">
					<div class="inner">

<!-- Boxes -->
<div class="thumbnails">

    <!-- Monocular Vision -->
    <div class="box">
        <a href="images/image_1.png" class="image fit"><img src="images/image_1.png" alt="" /></a>
        <div class="inner">
            <h3>Monocular Distance Estimator</h3>
            <p>This project uses both Monocular visions using a CNN regressor 
		    and Stereo Vision to detect the distance between pedestrians and an onboard camera.</p>
            <p>The pedestrians are detected using a YOLO5n model. 
		    The monocular vision provides a highly accurate regressor, with an error of less than 1meter. 
		    The Stereo vision provides an estimation of less than .5meter. 
	    </p>
		
	<p>Below, the watch demo shows the CNN regressor predicting multiple pedestrians in real time </p>
            <br>
            <br>
	    <a href="images/video_distances.mp4" class="button fit" data-poptrox="youtube,800x400">Watch Demo</a>
            <a href="https://github.com/EoghanOConnor/deep_learning_distance_estimator" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
        </div>
    </div>

    <!-- BCI -->
    <div class="box">
        <a href="images/bci_headset.png" class="image fit"><img src="images/bci_headset.png" alt="" /></a>
        <div class="inner">
            <h3>Machine learning applied to EEG signals</h3>
            <p>This project uses a CNN model to try classify when a userâ€™s thinking left and right. 100 billion neurons fire in the brain per second, causing high volume of noise.
		    Identifying different brain signals is difficult due to this. </p>
            <p>The below video shows the user thinking, First right (0:00-0:07), then left (0:07-0:14), then right (0:14-0:20).
		    The noise interference is noticeable due to overall brain activity.</p>
            <p>  </p>
            <br>
	    <br>
	    <a href="images/bci_video.mp4" class="button fit" data-poptrox="youtube,800x400">Watch Demo</a>
            <a href="https://github.com/EoghanOConnor/ML_OpenBCI" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
        </div>
    </div>

    <!-- DDT -->
    <div class="box">
        <a href="images/image_0.png" class="image fit"><img src="images/image_0.png" alt="" /></a>
        <div class="inner">
            <h3>Object discovery using DDT method</h3>
            <p>A Deep Descriptor Transforming (DDT) method is used to identify and locate the outline of objects in an image </p>
             <p>   This is done with unlabelled dataset rather than a labelled, 
		     which learns to identify primary objects in an image. This avoids the need for labelled data or for training a model.</p>
            <p>This is an advanced Machine learning technique, the published paper can be found here: https://arxiv.org/pdf/1707.06397.pdf </p>
	 	<p>  </p>
            <br>
	    <br>
	    <br>
            <a href="https://github.com/EoghanOConnor/Object_discovery_DDT_method" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
        </div>
    </div>

							<!-- Facial Verification -->
							<div class="box">
								<a href="images/image_2.png" class="image fit"><img src="images/image_2.png" alt="" /></a>
								<div class="inner">
									<h3>Facial Verification</h3>
									<p>
										Two separate images are passed into each Subnetwork CNN shown above. The networks are identical as they share the same weights.
										The Euclidean distance between the outputted is used to calculate the similarity between the two images.
										If the images pass a certain threshold the images are classified as a pair.
									</p>

									<p>
										This is an advanced facial recognition technique, published paper can be found here:  http://www.jips-k.org/q.jips?cp=pp&pn=621
									</p>
									<p>  </p>
									<br>
									<br>
									

									<a href="https://github.com/EoghanOConnor/facial_verification" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
								</div>
							</div>

							<!-- ResNet DenseNet -->
							<div class="box">
								<a href="images/image_3.png" class="image fit"><img src="images/image_3.png" alt="" /></a>
								<div class="inner">
									<h3>ResNet and DenseNet Object Classifier</h3>
									<p> This project uses ResNet and DenseNet for image classification.
										ResNet is a neural network architecture that uses skip connections to allow gradients to flow more easily during training,
										enabling deeper networks to be trained. DenseNet is a neural network architecture that connects all layers directly to each other,
										resulting in dense connections that allow information to flow more easily between layers.
									 </p>

									<p>
										These advanced models are published in the following paper: https://arxiv.org/pdf/1512.03385.pdf
									</p>
									<p>  </p>
									<br>
									<br>
									<a href="https://github.com/EoghanOConnor/ResNet_DenseNet_Object_classifier" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
								</div>
							</div>

							<!-- DQNs -->
							<div class="box">
								<a href="images/image_4.png" class="image fit"><img src="images/image_4.png" alt="" /></a>
								<div class="inner">
									<h3>Duelling DQN </h3>
									<p>
										This project uses a Duelling DQN to train an agent to play An Atari video game. The agent takes actions based on the current state. 
										The game returns a reward (score) to the agent indicating good or bad actions. This develops a Q-value for the agent's actions. 
										The agent develops an exploration vs exploitation policy in tandem with the Q values for previous actions by utilizing experience replay and target networks. 
										
										</p>

										<p>
										 This is a deep learning reinforcement model. 

									</p>
									<p>  </p>
									<br>
									<br>
									<a href="https://github.com/EoghanOConnor/rl_duelling_dqn_atari" target="_blank" class="button style3 fit" data-poptrox="youtube,800x400">View Repository</a>
								</div>
							</div>




						</div>

					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<div class="inner">
						<h2>Contact details</h2>
					
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/eoghan-o-connor-635065158/" target="_blank" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="mailto:eoghanfoconnor@gmail.com" class="icon fa-envelope"><span class="label">Email</span></a></li>
							<li><a href="https://github.com/EoghanOConnor" target="_blank" class="icon fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</div>
				</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

		

	</body>
</html>
